pekko.kafka {
  # Properties for org.apache.pekko.kafka.CommitterSettings can be
  # defined in this section or a configuration section with
  # the same layout.
  committer {
    # Maximum number of messages in a single commit batch
    max-batch = 1000

    # Maximum interval between commits
    max-interval = 10s

    # Parallelsim for async committing
    parallelism = 100
  }

  # Properties for pekko.kafka.ProducerSettings can be defined in this section or
  # a configuration section with the same layout.
  producer {
    # Config path of Apache Pekko Discovery method
    # "pekko.discovery" to use the Apache Pekko Discovery method configured for the ActorSystem
    discovery-method = pekko.discovery

    # Set a service name for use with Apache Pekko Discovery
    # https://pekko.apache.org/docs/pekko-connectors-kafka/current/discovery.html
    service-name = ""

    # Timeout for getting a reply from the discovery-method lookup
    resolve-timeout = 3 seconds

    # Tuning parameter of how many sends that can run in parallel.
    parallelism = 10000

    # Duration to wait for `KafkaConsumer.close` to finish.
    close-timeout = 60s

    # Call `KafkaProducer.close` when the stream is shutdown. This is important
    # to override to false when the producer instance is shared across multiple
    # producer stages.
    close-on-producer-stop = true

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the producer stages. Some blocking may occur.
    # When this value is empty, the dispatcher configured for the stream
    # will be used.
    use-dispatcher = "pekko.kafka.default-dispatcher"

    # The time interval to commit a transaction when using the
    # `Transactional.sink` or `Transactional.flow`
    eos-commit-interval = 100ms

    # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
    # can be defined in this configuration section.
    kafka-clients {
      // security.protocol=SSL
      // ssl.truststore.location=/var/private/ssl/kafka.client.truststore.jks
      // ssl.truststore.password=test1234
      // ssl.keystore.location=/var/private/ssl/kafka.client.keystore.jks
      // ssl.keystore.password=test1234
      // ssl.key.password=test1234
    }
  }

  # Properties for pekko.kafka.ConsumerSettings can be
  # defined in this section or a configuration section with
  # the same layout.
  consumer {
    # Config path of Apache Pekko Discovery method
    # "pekko.discovery" to use the Apache Pekko Discovery method configured for the ActorSystem
    discovery-method = pekko.discovery

    # Set a service name for use with Apache Pekko Discovery
    # https://pekko.apache.org/docs/pekko-connectors-kafka/current/discovery.html
    service-name = ""

    # Timeout for getting a reply from the discovery-method lookup
    resolve-timeout = 3 seconds

    # Tuning property of scheduled polls.
    # Controls the interval from one scheduled poll to the next.
    poll-interval = 50ms

    # Tuning property of the `KafkaConsumer.poll` parameter. Note that non-zero
    # value means that the thread that is executing the stage will be blocked.
    # See also the `wakup-timeout` setting below.
    poll-timeout = 50ms

    # The stage will delay stopping the internal actor to allow processing of
    # messages already in the stream (required for successful committing).
    # Prefer use of `DrainingControl` over a large stop-timeout.
    #
    # IMPORTANT: Keep this timeout very low, to try and prevent losing messages
    #            upon connection reset by peer scenarios!
    stop-timeout = 2ms

    # Duration to wait for `KafkaConsumer.close` to finish.
    close-timeout = 20s

    # If offset commit requests are not completed within this timeout the
    # returned Future is completed `CommitTimeoutException`.
    commit-timeout = 15s

    # If commits take longer than this time a warning is logged
    commit-time-warning = 1s

    # If set to a finite duration, the consumer will re-send the last committed
    # offsets periodically for all assigned partitions.
    # See https://issues.apache.org/jira/browse/KAFKA-4682.
    commit-refresh-interval = infinite

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the KafkaConsumerActor. Some blocking may occur.
    use-dispatcher = "pekko.kafka.default-dispatcher"

    # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
    # can be defined in this configuration section.
    kafka-clients {
      # Disable auto-commit by default
      enable.auto.commit = false
      // security.protocol=SSL
      // ssl.truststore.location=/var/private/ssl/kafka.client.truststore.jks
      // ssl.truststore.password=test1234
      // ssl.keystore.location=/var/private/ssl/kafka.client.keystore.jks
      // ssl.keystore.password=test1234
      // ssl.key.password=test1234
    }

    # Time to wait for pending requests when a partition is closed
    wait-close-partition = 500ms

    # Limits the query to Kafka for a topic's position
    position-timeout = 5s

    # When using `AssignmentOffsetsForTimes` subscriptions: timeout for the
    # call to Kafka's API
    offset-for-times-timeout = 5s

    # Timeout for pekko.kafka.Metadata requests. This value is used instead of
    # Kafka's default from `default.api.timeout.ms` which is 1 minute.
    metadata-request-timeout = 5s

    # Interval for checking that transaction was completed before closing the consumer.
    # Used in the transactional flow for exactly-once-semantics processing.
    eos-draining-check-interval = 30ms

    # Issue warnings when a call to a partition assignment handler method takes
    # longer than this.
    partition-handler-warning = 5s

    # Settings for checking the connection to the Kafka broker. Connection checking uses `listTopics` requests with the timeout
    # configured by `consumer.metadata-request-timeout`
    connection-checker {

      #Flag to turn on connection checker
      enable = false

      # Amount of attempts to be performed after a first connection failure occurs
      # Required, non-negative integer
      max-retries = 3

      # Interval for the connection check. Used as the base for exponential retry.
      check-interval = 15s

      # Check interval multiplier for backoff interval
      # Required, positive number
      backoff-factor = 2.0
    }

    # Protect against server-side bugs that cause Kafka to temporarily "lose" the latest offset for a consumer, which
    # then causes the Kafka consumer to follow its normal 'auto.offset.reset' behavior. For 'earliest', these settings
    # allow the client to detect and attempt to recover from this issue. For 'none' and 'latest', these settings will
    # only add overhead. See
    # for more information
    offset-reset-protection {
      # turns on reset protection
      enable = false
      # if consumer gets a record with an offset that is more than this number of offsets back from the previously
      # requested offset, it is considered a reset
      offset-threshold = 9223372036854775807
      # if the record is more than this duration earlier the last received record, it is considered a reset
      time-threshold = 100000 days
    }
  }
}